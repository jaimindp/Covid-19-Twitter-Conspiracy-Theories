{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tweepy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_filepath = \"QAnon_users_id.csv\"\n",
    "timeline_filepath = \"../../covid_data/timeline_data/\"\n",
    "timeline_object_json = \"../../covid_data/timeline_object_json/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156389"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"###########################################\")\n",
    "# keywords_df = pd.read_csv(\"all_conspiracies.csv\")\n",
    "# print(keywords_df.shape)\n",
    "c_users = list(pd.read_csv('QAnon_users_id.csv').user_id)\n",
    "len(c_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your credentials here\n",
    "twitter_keys = {\n",
    "        'consumer_key':        'DPIuUoHQsmaeK7UCyQZPxk1pD',\n",
    "        'consumer_secret':     'SLDDw1VCdbF1ZpWl8xnNRekgw2Occd7ltVPuxo4tfyTZRPd8aq',\n",
    "        'access_token_key':    '1239432784319406080-utlL3ABCF0F7TK1Kcg2QBMHy2FfvTZ',\n",
    "        'access_token_secret': 'rHxi7iYnyDOeK9eE9t7BNi7KJTstAGaFlOINSx3qIpTFB'\n",
    "    }\n",
    "\n",
    "#Setup access to API\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = []\n",
    "    \n",
    "for id in c_users:\n",
    "    tweet_list_json = []\n",
    "    tweet_list_csv = []\n",
    "    collect_user_data = 0\n",
    "    \n",
    "    try:\n",
    "        for statuses in tweepy.Cursor(api.user_timeline, user_id=id, tweet_mode=\"extended\", count = 200).pages():\n",
    "            for status in statuses:\n",
    "                json_str = json.dumps(status._json)\n",
    "                parsed = json.loads(json_str)\n",
    "                tweet_list_json.append(json.dumps(parsed, indent=4, sort_keys=True))\n",
    "\n",
    "            #     https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object\n",
    "                if(collect_user_data == 0):\n",
    "                    user_list.append([parsed[\"user\"][\"id\"], parsed[\"user\"][\"id_str\"], parsed[\"user\"][\"name\"], \n",
    "                                parsed[\"user\"][\"screen_name\"],\n",
    "                                parsed[\"user\"][\"location\"],\n",
    "                                parsed[\"user\"][\"created_at\"], parsed[\"user\"][\"description\"], \n",
    "                                parsed[\"user\"][\"friends_count\"],\n",
    "                                parsed[\"user\"][\"followers_count\"], parsed[\"user\"][\"listed_count\"], \n",
    "                                parsed[\"user\"][\"url\"],\n",
    "                                parsed[\"user\"][\"favourites_count\"], parsed[\"user\"][\"statuses_count\"], \n",
    "                                parsed[\"user\"][\"default_profile_image\"],\n",
    "                                parsed[\"user\"][\"default_profile\"], \n",
    "                                parsed[\"user\"][\"profile_image_url_https\"]])\n",
    "                    collect_user_data = 1\n",
    "\n",
    "                try:\n",
    "                    in_reply_to_user_id = parsed[\"in_reply_to_user_id\"]\n",
    "                except:\n",
    "                    in_reply_to_user_id = \"\"\n",
    "\n",
    "                try:\n",
    "                    in_reply_to_user_id = parsed[\"in_reply_to_user_id\"]\n",
    "                except:\n",
    "                    in_reply_to_user_id = \"\"\n",
    "\n",
    "                try:\n",
    "                    possibly_sensitive = parsed[\"possibly_sensitive\"]\n",
    "                except:\n",
    "                    possibly_sensitive = \"\"\n",
    "\n",
    "                try:\n",
    "                    in_reply_to_status_id = parsed[\"in_reply_to_status_id\"]\n",
    "                except:\n",
    "                    in_reply_to_status_id = \"\"\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_created_at =  parsed[\"retweeted_status\"][\"created_at\"]\n",
    "                except:\n",
    "                    retweeted_status_created_at = \"\"\n",
    "\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_id =  parsed[\"retweeted_status\"][\"id\"]\n",
    "                except:\n",
    "                    retweeted_status_id = \"\"\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_favorite_count =  parsed[\"retweeted_status\"][\"favorite_count\"]\n",
    "                except:\n",
    "                    retweeted_status_favorite_count = \"\"\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_retweet_count = parsed[\"retweeted_status\"][\"retweet_count\"]\n",
    "                except:\n",
    "                    retweeted_status_retweet_count = \"\"\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_geo = parsed[\"retweeted_status\"][\"coordinates\"]\n",
    "                except:\n",
    "                    retweeted_status_geo = \"\"\n",
    "\n",
    "                try:\n",
    "                    retweeted_status_full_text = parsed[\"retweeted_status\"][\"full_text\"]\n",
    "                except:\n",
    "                    retweeted_status_full_text = \"\"\n",
    "\n",
    "                try:    \n",
    "                    retweeted_status_entities_urls = parsed[\"retweeted_status\"]['entities'][\"urls\"]\n",
    "                except:\n",
    "                    retweeted_status_entities_urls = \"\"\n",
    "\n",
    "                try:    \n",
    "                    retweeted_status_entities_user_mentions = parsed[\"retweeted_status\"]['entities'][\"user_mentions\"]\n",
    "                except:\n",
    "                    retweeted_status_entities_user_mentions = \"\"\n",
    "\n",
    "                try:    \n",
    "                    retweeted_status_entities_hashtags = parsed[\"retweeted_status\"]['entities'][\"hashtags\"]\n",
    "                except:\n",
    "                    retweeted_status_entities_hashtags = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_created_at = parsed[\"quoted_status\"][\"created_at\"]\n",
    "                except:\n",
    "                    quoted_status_created_at = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_full_text = parsed[\"quoted_status\"][\"full_text\"]\n",
    "                except:\n",
    "                    quoted_status_full_text = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_entities_urls = parsed[\"quoted_status\"]['entities'][\"urls\"]\n",
    "                except:\n",
    "                    quoted_status_entities_urls = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_entities_user_mentions = parsed[\"quoted_status\"]['entities'][\"user_mentions\"]\n",
    "                except:\n",
    "                    quoted_status_entities_user_mentions = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_entities_hashtags = parsed[\"quoted_status\"]['entities'][\"hashtags\"]\n",
    "                except:\n",
    "                    quoted_status_entities_hashtags = \"\"\n",
    "\n",
    "                try:    \n",
    "                    quoted_status_favorite_count = parsed[\"quoted_status\"][\"favorite_count\"]\n",
    "                except:\n",
    "                    quoted_status_favorite_count = \"\"\n",
    "\n",
    "                try:\n",
    "                    quoted_status_retweet_count = parsed[\"quoted_status\"][\"retweet_count\"]\n",
    "                except:\n",
    "                    quoted_status_retweet_count = \"\"\n",
    "\n",
    "                try:\n",
    "                    quoted_status_geo = parsed[\"quoted_status\"][\"coordinates\"]\n",
    "                except:\n",
    "                    quoted_status_geo = \"\"\n",
    "\n",
    "                try:\n",
    "                    quoted_status_id = parsed[\"quoted_status_id\"]\n",
    "                except:\n",
    "                    quoted_status_id = \"\"\n",
    "\n",
    "                is_quote_status = parsed[\"is_quote_status\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                tweet_list_csv.append([parsed[\"created_at\"], parsed[\"full_text\"], parsed[\"lang\"], parsed[\"id\"], parsed[\"id_str\"],\n",
    "                                     parsed[\"place\"], parsed[\"favorite_count\"], parsed[\"retweet_count\"], in_reply_to_user_id,\n",
    "                                     possibly_sensitive, in_reply_to_status_id, parsed[\"entities\"][\"hashtags\"],\n",
    "                                     parsed[\"entities\"][\"urls\"], parsed[\"entities\"][\"user_mentions\"], \n",
    "                                     retweeted_status_created_at, retweeted_status_id,\n",
    "                                     retweeted_status_favorite_count, retweeted_status_retweet_count, retweeted_status_geo,\n",
    "                                     retweeted_status_full_text, retweeted_status_entities_urls, retweeted_status_entities_user_mentions,\n",
    "                                     retweeted_status_entities_hashtags, quoted_status_created_at, quoted_status_full_text,\n",
    "                                     quoted_status_entities_urls, quoted_status_entities_user_mentions,\n",
    "                                     quoted_status_entities_hashtags, quoted_status_favorite_count, \n",
    "                                     quoted_status_retweet_count,\n",
    "                                     quoted_status_geo, quoted_status_id, is_quote_status])\n",
    "\n",
    "                df_tweet_timeline = pd.DataFrame(tweet_list_csv, columns = ['created_at', 'full_text', 'lang', 'id', 'id_string',\n",
    "                                                                        'place', 'favorite_count', 'retweet_count',\"in_reply_to_user_id\",\n",
    "                \"possibly_sensitive\", 'in_reply_to_status_id', 'hashtags', 'urls', 'user_mentions',\n",
    "                                                    'retweeted_status_created_at', 'retweeted_status_id',\n",
    "                'retweeted_status_favorite_count', 'retweeted_status_retweet_count', 'retweeted_status_coordinates',\n",
    "                                                                        'retweeted_status_full_text',\n",
    "                'retweeted_status_entities_urls', 'retweeted_status_entities_user_mentions', 'retweeted_status_entities_hashtags',\n",
    "                'quoted_status_created_at', 'quoted_status_full_text', 'quoted_status_entities_urls',\n",
    "                                                                        'quoted_status_entities_user_mentions',\n",
    "                'quoted_status_entities_hashtags', 'quoted_status_favorite_count', 'quoted_status_retweet_count',\n",
    "                'quoted_status_coordinates', 'quoted_status_id', 'is_quote_status'])\n",
    "    except:\n",
    "        print(\"error for user id: %d\" % (id))\n",
    "        continue\n",
    "\n",
    "    df_tweet_timeline.to_csv(timeline_filepath+str(id)+\".csv\", index=False)\n",
    "    PIK = timeline_object_json+str(id)+\".dat\"\n",
    "   \n",
    "    with open(PIK, \"wb\") as f:\n",
    "        pickle.dump(tweet_list_json, f)\n",
    "#     print(len(tweet_list_json))\n",
    "#     print(df_tweet_timeline.shape)\n",
    "\n",
    "# print(\"jjjjj\")\n",
    "# print(len(user_list))\n",
    "df_user_details = pd.DataFrame(user_list, columns = ['id','id_str','name',\n",
    "                'screen_name', 'location', 'created_at','description','friends_count',\n",
    "                'followers_count','listed_count',\n",
    "                'url', 'favourites_count', 'statuses_count', \n",
    "                'default_profile_image', \"default_profile\", 'profile_image_url_https'])\n",
    "\n",
    "# print(df_user_details.shape)\n",
    "df_user_details.to_csv(user_filepath+\"user_data\"+\".csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
